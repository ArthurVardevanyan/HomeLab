# Source: vault/templates/server-statefulset.yaml
# StatefulSet to run the actual vault server cluster.
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: vault
  namespace: vault
  labels:
    app.kubernetes.io/name: vault
    app.kubernetes.io/instance: vault
    app: vault
spec:
  serviceName: vault-internal
  podManagementPolicy: Parallel
  replicas: 3
  # updateStrategy:
  #   type: OnDelete
  selector:
    matchLabels:
      app.kubernetes.io/name: vault
      app.kubernetes.io/instance: vault
      component: server
      app: vault
  template:
    metadata:
      labels:
        app.kubernetes.io/name: vault
        app.kubernetes.io/instance: vault
        component: server
        app: vault
    spec:
      topologySpreadConstraints:
        - maxSkew: 1
          topologyKey: topology.kubernetes.io/zone
          whenUnsatisfiable: DoNotSchedule
          labelSelector:
            matchLabels:
              app.kubernetes.io/name: vault
        - maxSkew: 1
          topologyKey: kubernetes.io/hostname
          whenUnsatisfiable: DoNotSchedule
          labelSelector:
            matchLabels:
              app.kubernetes.io/name: vault
      terminationGracePeriodSeconds: 10
      serviceAccountName: vault-sa
      securityContext:
        runAsNonRoot: true
      hostNetwork: false
      volumes:
        - name: config
          configMap:
            name: vault-config
        - name: gcp-credentials-request
          configMap:
            name: gcp-credentials-request
            defaultMode: 420
        - name: serviceaccount-token
          projected:
            sources:
              - serviceAccountToken:
                  audience: openshift
                  expirationSeconds: 3600
                  path: token
            defaultMode: 420
        - name: vault-cert
          secret:
            secretName: vault-cert
        - name: home
          emptyDir: {}
      containers:
        - name: vault
          image: docker.io/hashicorp/vault:1.18.1@sha256:3580fa352195aa7e76449cb8fadeef6d2f90a454c38982d30cf094e9013be786
          imagePullPolicy: IfNotPresent
          command:
            - "/bin/sh"
            - "-ec"
          args:
            - |
              cp /vault/config/extraconfig-from-values.hcl /tmp/storageconfig.hcl;
              [ -n "${HOST_IP}" ] && sed -Ei "s|HOST_IP|${HOST_IP?}|g" /tmp/storageconfig.hcl;
              [ -n "${POD_IP}" ] && sed -Ei "s|POD_IP|${POD_IP?}|g" /tmp/storageconfig.hcl;
              [ -n "${HOSTNAME}" ] && sed -Ei "s|HOSTNAME|${HOSTNAME?}|g" /tmp/storageconfig.hcl;
              [ -n "${API_ADDR}" ] && sed -Ei "s|API_ADDR|${API_ADDR?}|g" /tmp/storageconfig.hcl;
              [ -n "${TRANSIT_ADDR}" ] && sed -Ei "s|TRANSIT_ADDR|${TRANSIT_ADDR?}|g" /tmp/storageconfig.hcl;
              [ -n "${RAFT_ADDR}" ] && sed -Ei "s|RAFT_ADDR|${RAFT_ADDR?}|g" /tmp/storageconfig.hcl;
              /usr/local/bin/docker-entrypoint.sh vault server -config=/tmp/storageconfig.hcl
          resources:
            requests:
              memory: "128Mi"
              cpu: "35m"
            limits:
              memory: "768Mi"
              cpu: "150m"
          securityContext:
            allowPrivilegeEscalation: false
          env:
            - name: GOOGLE_APPLICATION_CREDENTIALS
              value: /var/run/secrets/google/credentials_config.json
            - name: CLOUDSDK_AUTH_CREDENTIAL_FILE_OVERRIDE
              value: /var/run/secrets/google/credentials_config.json
            - name: HOST_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: VAULT_K8S_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: VAULT_K8S_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: VAULT_ADDR
              value: "http://127.0.0.1:8200"
            - name: VAULT_API_ADDR
              value: "http://$(POD_IP):8200"
            - name: SKIP_CHOWN
              value: "true"
            - name: SKIP_SETCAP
              value: "true"
            - name: HOSTNAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: VAULT_CLUSTER_ADDR
              value: "http://$(HOSTNAME).vault-internal:8201"
            - name: HOME
              value: "/home/vault"

          volumeMounts:
            - name: data
              mountPath: /vault/data

            - name: config
              mountPath: /vault/config

            - name: home
              mountPath: /home/vault
            - mountPath: /vault/cert
              name: vault-cert
            - name: gcp-credentials-request
              readOnly: true
              mountPath: /var/run/secrets/google
            - name: serviceaccount-token
              readOnly: true
              mountPath: /var/run/secrets/openshift/serviceaccount
          ports:
            - containerPort: 8200
              name: http
            - containerPort: 8201
              name: https-internal
            - containerPort: 8202
              name: http-rep
          readinessProbe:
            # Check status; unsealed vault servers return 0
            # The exit code reflects the seal status:
            #   0 - unsealed
            #   1 - error
            #   2 - sealed
            exec:
              command: ["/bin/sh", "-ec", "vault status -tls-skip-verify"]
            failureThreshold: 2
            initialDelaySeconds: 5
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 3
          lifecycle:
            # Vault container doesn't receive SIGTERM from Kubernetes
            # and after the grace period ends, Kube sends SIGKILL.  This
            # causes issues with graceful shutdowns such as deregistering itself
            # from Consul (zombie services).
            preStop:
              exec:
                command: [
                    "/bin/sh",
                    "-c",
                    # Adding a sleep here to give the pod eviction a
                    # chance to propagate, so requests will not be made
                    # to this pod while it's terminating
                    "sleep 5 && kill -SIGTERM $(pidof vault)",
                  ]

  volumeClaimTemplates:
    - metadata:
        name: data

      spec:
        accessModes:
          - ReadWriteOnce
        resources:
          requests:
            storage: 10Gi
        storageClassName: rook-ceph-block
